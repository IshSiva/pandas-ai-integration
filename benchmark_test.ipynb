{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandasai import SmartDataframe\n",
    "from pandasai.llm import OpenAI\n",
    "import numpy as np\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(api_token=\"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\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup EvaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to EvaDB\n"
     ]
    }
   ],
   "source": [
    "import evadb\n",
    "\n",
    "cursor = evadb.connect().cursor()\n",
    "print(\"Connected to EvaDB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<evadb.models.storage.batch.Batch at 0x14fc91590>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.query(\"DROP FUNCTION IF EXISTS ChatWithPandas;\").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created Function\n"
     ]
    }
   ],
   "source": [
    "create_function_query = f\"\"\"CREATE FUNCTION IF NOT EXISTS ChatWithPandas\n",
    "            IMPL  './functions/chat_with_df.py';\n",
    "            \"\"\"\n",
    "cursor.query(create_function_query).execute()\n",
    "print(\"Created Function\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<evadb.models.storage.batch.Batch at 0x14f9b9210>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_db = \"\"\"CREATE DATABASE IF NOT EXISTS sqlite_data WITH ENGINE = 'sqlite', PARAMETERS = {\n",
    "     \"database\": \"evadb.db\"\n",
    "};\"\"\"\n",
    "\n",
    "cursor.query(sql_db).execute()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load into SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "csv_file = 'clean_ml_data/Movie/duplicates/dirty_train.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "database_file = 'evadb.db'\n",
    "conn = sqlite3.connect(database_file)\n",
    "\n",
    "table_name = 'DUPL_DATA'\n",
    "df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of cleaning performance\n",
    "\n",
    "## Remove Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dupl_df = pd.read_csv(\"clean_ml_data/Movie/duplicates/clean_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_dupl_df = pd.read_csv(\"clean_ml_data/Movie/duplicates/dirty_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PandasAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_dirty_dupl_df = SmartDataframe(dirty_dupl_df, config={\"llm\": llm})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_clean_dupl_df = pd_dirty_dupl_df.clean_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EvaAIDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_file = 'evadb.db'\n",
    "sql_conn = sqlite3.connect(database_file)\n",
    "\n",
    "sql_cursor = sql_conn.cursor()\n",
    "\n",
    "table_name = \"DUPL_DATA\"\n",
    "sql_cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "columns = [row[1] for row in sql_cursor.fetchall()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['title',\n",
       " 'genres',\n",
       " 'budget',\n",
       " 'language',\n",
       " 'duration',\n",
       " 'year',\n",
       " 'vote_count',\n",
       " 'score']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_query = f\"\"\" SELECT ChatWithPandas('cleaning', 'remove duplicate rows based on all columns from the dataframe',\n",
    "            title, genres, budget, language, duration, year, vote_count, score) FROM sqlite_data.DUPL_DATA;\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "print(chat_query)\n",
    "result = cursor.query(chat_query).execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "eva_clean_dupl_df = pd.read_csv(\"cleaned_df.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6510"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eva_clean_dupl_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dirty df: 6531\n",
      "Lenght of Ideal cleaned df: 4419 \n",
      "Length of PandasAI library cleaning: 6531\n",
      "Length of EvaAI cleaned df: 6510\n"
     ]
    }
   ],
   "source": [
    "print(f\"Length of dirty df: {len(dirty_dupl_df)}\")\n",
    "print(f\"Lenght of Ideal cleaned df: {len(clean_dupl_df)} \")\n",
    "print(f\"Length of PandasAI library cleaning: {len(pd_clean_dupl_df)}\")\n",
    "print(f\"Length of EvaAI cleaned df: {len(eva_clean_dupl_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>budget</th>\n",
       "      <th>language</th>\n",
       "      <th>duration</th>\n",
       "      <th>year</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Play It to the Bone</td>\n",
       "      <td>1</td>\n",
       "      <td>24000000</td>\n",
       "      <td>en</td>\n",
       "      <td>124</td>\n",
       "      <td>1999</td>\n",
       "      <td>53</td>\n",
       "      <td>5.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban</td>\n",
       "      <td>0</td>\n",
       "      <td>130000000</td>\n",
       "      <td>en</td>\n",
       "      <td>141</td>\n",
       "      <td>2004</td>\n",
       "      <td>5877</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      title  genres     budget language  \\\n",
       "0                       Play It to the Bone       1   24000000       en   \n",
       "1  Harry Potter and the Prisoner of Azkaban       0  130000000       en   \n",
       "\n",
       "   duration  year  vote_count  score  \n",
       "0       124  1999          53    5.7  \n",
       "1       141  2004        5877    7.7  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.read_csv(\"clean_ml_data/Movie/duplicates/dirty_train.csv\")\n",
    "tmp.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4373"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#when manually perform a \n",
    "len(tmp.drop_duplicates(subset='title'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_missing_df = pd.read_csv(\"clean_ml_data/Titanic/missing_values/impute_mean_dummy_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_missing_df = pd.read_csv(\"clean_ml_data/Titanic/missing_values/dirty_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PandasAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_dirty_missing_df = SmartDataframe(dirty_missing_df, config={\"llm\": llm})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_clean_missing_df = pd_dirty_missing_df.impute_missing_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EvaAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "624"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_file = 'evadb.db'\n",
    "conn = sqlite3.connect(database_file)\n",
    "\n",
    "table_name = 'MISSING_DATA'\n",
    "dirty_missing_df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp', 'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "sql_cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "columns = [row[1] for row in sql_cursor.fetchall()]\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SELECT ChatWithPandas('cleaning',\n",
      "    'impute null values with the mean value of the column. compute the mean for each column not for entire dataset. if it is a string column then replace with empty string',\n",
      "     PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked) FROM sqlite_data.MISSING_DATA;\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ishsiva/Masters/Special Problems/DB Lab/pandas-ai-integration/datastructure/aidDataframe.py:13: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  self.pd_df = df\n"
     ]
    }
   ],
   "source": [
    "chat_query2 = f\"\"\" SELECT ChatWithPandas('cleaning',\n",
    "    'impute null values with the mean value of the column. compute the mean for each column not for entire dataset. if it is a string column then replace with empty string',\n",
    "     PassengerId, Survived, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked) FROM sqlite_data.MISSING_DATA;\n",
    "\"\"\"\n",
    "\n",
    "print(chat_query2)\n",
    "result2 = cursor.query(chat_query2).execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "eva_clean_missing_df = pd.read_csv(\"cleaned_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Nos of null values in original dirty df: {dirty_missing_df.isnull().sum()}\")\n",
    "print(f\"Nos of null values in original clean df: {clean_missing_df.isnull().sum()}\")\n",
    "print(f\"Nos of null values in pandas ai clean df: {pd_clean_missing_df.isnull().sum()}\")\n",
    "print(f\"Nos of null values in eva clean df: {eva_clean_missing_df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_outliers_df = pd.read_csv(\"clean_ml_data/Airbnb/outliers/clean_SD_impute_mean_dummy_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_outliers_df = pd.read_csv(\"clean_ml_data/Airbnb/outliers/dirty_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PandasAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_dirty_outliers_df = SmartDataframe(dirty_outliers_df, config={\"llm\": llm})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_clean_outliers_df = pd_dirty_outliers_df.chat(\"Replace values in Price column that are more than 2 std deviations from mean with the mean values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EvaAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18406"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database_file = 'evadb.db'\n",
    "conn = sqlite3.connect(database_file)\n",
    "\n",
    "table_name = 'OUTLIERS_DATA'\n",
    "dirty_outliers_df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bathrooms', 'Bedrooms', 'Beds', 'LocationName', 'NumGuests', 'NumReviews', 'Price', 'Rating', 'latitude', 'longitude', 'zipcode', 'pop2016', 'pop2010', 'pop2000', 'cost_living_index (US avg. = 100)', 'land_area (sq.mi.)', 'water_area (sq.mi.)', 'pop_density (people per mile)', 'number of males', 'number of females', 'prop taxes paid 2016', 'median taxes (with mortgage', 'median taxes (no mortgage)', 'median house value', 'median houshold income', 'median monthly owner costs (with mortgage)', 'median monthly owner costs (no mortgage)', 'median gross rent', 'median asking price for vacant for-sale home/condo', 'unemployment (%)', 'Number of Homes', 'Count of Abnb', 'Density of Abnb (%)', 'Average Abnb Price (by zipcode)', 'Average NumReviews (by zipcode)', 'Average Rating (by zipcode)', 'Average Number of Bathrooms (by zipcode)', 'Average Number of Bedrooms (by zipcode)', 'Average Number of Beds (by zipcode)', 'Average Number of Guests (by zipcode)']\n"
     ]
    }
   ],
   "source": [
    "sql_cursor.execute(f\"PRAGMA table_info({table_name})\")\n",
    "columns = [row[1] for row in sql_cursor.fetchall()]\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SELECT ChatWithPandas('cleaning',\n",
      "    'Replace values in Price column that are more than 2 std deviations from mean with the mean values',\n",
      "     LocationName, Price, Rating, latitude) FROM sqlite_data.OUTLIERS_DATA;\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ishsiva/Masters/Special Problems/DB Lab/pandas-ai-integration/datastructure/aidDataframe.py:13: UserWarning: Pandas doesn't allow columns to be created via a new attribute name - see https://pandas.pydata.org/pandas-docs/stable/indexing.html#attribute-access\n",
      "  self.pd_df = df\n"
     ]
    }
   ],
   "source": [
    "chat_query3 = f\"\"\" SELECT ChatWithPandas('cleaning',\n",
    "    'Replace values in Price column that are more than 2 std deviations from mean with the mean values',\n",
    "     LocationName, Price, Rating, latitude) FROM sqlite_data.OUTLIERS_DATA;\n",
    "\"\"\"\n",
    "\n",
    "print(chat_query3)\n",
    "result = cursor.query(chat_query2).execute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<evadb.models.storage.batch.Batch at 0x153563010>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "eva_clean_outliers_df = pd.read_csv(\"cleaned_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value in Price: 999.0\n",
      "Max value in Price: nan\n",
      "Max value in Price: 326.0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Price'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Masters/Special Problems/DB Lab/pandas-ai-integration/pai_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/Masters/Special Problems/DB Lab/pandas-ai-integration/pai_env/lib/python3.11/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/Masters/Special Problems/DB Lab/pandas-ai-integration/pai_env/lib/python3.11/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5745\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:5753\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Price'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/Users/ishsiva/Masters/Special Problems/DB Lab/pandas-ai-integration/benchmark_test.ipynb Cell 52\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ishsiva/Masters/Special%20Problems/DB%20Lab/pandas-ai-integration/benchmark_test.ipynb#Y115sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMax value in Price: \u001b[39m\u001b[39m{\u001b[39;00mclean_outliers_df[\u001b[39m'\u001b[39m\u001b[39mPrice\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmax()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ishsiva/Masters/Special%20Problems/DB%20Lab/pandas-ai-integration/benchmark_test.ipynb#Y115sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMax value in Price: \u001b[39m\u001b[39m{\u001b[39;00mpd_clean_outliers_df[\u001b[39m'\u001b[39m\u001b[39mPrice\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmax()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ishsiva/Masters/Special%20Problems/DB%20Lab/pandas-ai-integration/benchmark_test.ipynb#Y115sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMax value in Price: \u001b[39m\u001b[39m{\u001b[39;00meva_clean_outliers_df[\u001b[39m'\u001b[39;49m\u001b[39mPrice\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mmax()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ishsiva/Masters/Special%20Problems/DB%20Lab/pandas-ai-integration/benchmark_test.ipynb#Y115sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# print(f\"Nos of null values in pandas ai clean df: {pd_clean_missing_df.isnull().sum()}\")\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ishsiva/Masters/Special%20Problems/DB%20Lab/pandas-ai-integration/benchmark_test.ipynb#Y115sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# print(f\"Nos of null values in eva clean df: {eva_clean_missing_df.isnull().sum()}\")\u001b[39;00m\n",
      "File \u001b[0;32m~/Masters/Special Problems/DB Lab/pandas-ai-integration/pai_env/lib/python3.11/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3808\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Masters/Special Problems/DB Lab/pandas-ai-integration/pai_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:3804\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3803\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Price'"
     ]
    }
   ],
   "source": [
    "print(f\"Max value in Price: {dirty_outliers_df['Price'].max()}\")\n",
    "print(f\"Max value in Price: {clean_outliers_df['Price'].max()}\")\n",
    "print(f\"Max value in Price: {pd_clean_outliers_df['Price'].max()}\")\n",
    "print(f\"Max value in Price: {eva_clean_outliers_df['Price'].max()}\")\n",
    "# print(f\"Nos of null values in pandas ai clean df: {pd_clean_missing_df.isnull().sum()}\")\n",
    "# print(f\"Nos of null values in eva clean df: {eva_clean_missing_df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
